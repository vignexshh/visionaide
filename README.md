# visionaide
Here's a markdown tutorial for setting up and running the provided Gradio app, complete with documentation. This tutorial can be used as a README.md file for a GitHub repository.

```markdown
# Gradio Object Detection and Text-to-Speech Application

This repository contains a Gradio application for object detection and text-to-speech using Mediapipe, Tesseract, and gTTS.

## Table of Contents
- [Prerequisites](#prerequisites)
- [Setup](#setup)
- [Running the Application](#running-the-application)
- [Application Overview](#application-overview)

## Prerequisites

Before you begin, ensure you have met the following requirements:
- Python 3.7 or higher
- Pip (Python package installer)
- An internet connection for downloading dependencies

## Setup

1. **Clone the Repository**
   
   Clone this repository to your local machine using:
   ```sh
   git clone https://github.com/your-username/your-repo-name.git
   cd your-repo-name
   ```

2. **Create and Activate a Virtual Environment**

   It's a good practice to use a virtual environment to manage your dependencies. You can create and activate a virtual environment using:
   ```sh
   python3 -m venv venv
   source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
   ```

3. **Install Dependencies**

   Install the required Python packages using pip:
   ```sh
   pip install -r requirements.txt
   ```

   Create a `requirements.txt` file with the following contents:
   ```txt
   gradio
   numpy
   opencv-python
   mediapipe
   gtts
   pytesseract
   ```

4. **Download Mediapipe Model**

   Ensure you have the Mediapipe model `efficientdet.tflite` in your project directory. You can download it from the [official Mediapipe repository](https://github.com/google/mediapipe).

5. **Install Tesseract-OCR**

   Install Tesseract-OCR on your machine:
   - On Ubuntu:
     ```sh
     sudo apt-get install tesseract-ocr
     ```
   - On Windows, download the installer from [Tesseract at UB Mannheim](https://github.com/UB-Mannheim/tesseract/wiki).

6. **Install mpg123**

   `mpg123` is required to play the MP3 files generated by gTTS:
   - On Ubuntu:
     ```sh
     sudo apt-get install mpg123
     ```
   - On Windows, download and install from the [official website](https://www.mpg123.de/download.shtml).

## Running the Application

To run the Gradio application, execute the following command in your terminal:
```sh
python app.py
```

This will start the Gradio interface on `http://127.0.0.1:7860`. Open this URL in your web browser to interact with the application.

## Application Overview

The application consists of the following main components:

### Object Detection
- **Function**: Detects objects in an uploaded image and draws bounding boxes around them.
- **Implementation**: Utilizes Mediapipe's object detection model.

### Text Detection
- **Function**: Detects and extracts text from an uploaded image.
- **Implementation**: Utilizes Tesseract OCR.

### Text-to-Speech
- **Function**: Converts text to speech and plays the generated audio.
- **Implementation**: Utilizes gTTS (Google Text-to-Speech).

### Gradio Interface
- **Components**: 
  - Image upload input
  - Annotated image output
  - Textbox for detection results
  - Textbox for detected text
  - Button to play detected text as speech
  - Button to reset the interface

### Code Overview

#### Main Functions
- `visualize(image, detection_result)`: Draws bounding boxes on the image.
- `detect_objects(image_path)`: Detects objects in the image and returns annotated image and detection texts.
- `detect_text(image_path)`: Detects and extracts text from the image.
- `text_to_speech(text)`: Converts text to speech using gTTS and plays the audio.
- `main(image)`: Main function that processes the uploaded image.
- `speak(text)`: Generates and plays summary TTS from the detected objects.
- `reset()`: Resets the interface outputs.

#### Gradio Blocks
```python
with gr.Blocks() as app:
    with gr.Row():
        with gr.Column():
            img_input = gr.Image(type="filepath", label="Upload Image")
            output_image = gr.Image(type="numpy", label="Annotated Image")
            output_text = gr.Textbox(label="Detection Results")
            output_text_detected = gr.Textbox(label="Detected Text")
        
        with gr.Column():
            speak_button = gr.Button("Speak Now")
            reset_button = gr.Button("New Image")
            
            speak_button.click(speak, inputs=output_text, outputs=gr.Textbox())
            reset_button.click(reset, outputs=[output_image, output_text, output_text_detected])
            
    img_input.change(main, inputs=img_input, outputs=[output_image, output_text, output_text_detected])

app.launch()
```

This block creates the Gradio interface with image upload, text output, and button functionalities.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.

## Acknowledgements

- [Gradio](https://gradio.app)
- [Mediapipe](https://mediapipe.dev)
- [gTTS](https://gtts.readthedocs.io)
- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)

---

Feel free to open an issue or submit a pull request if you have any questions or suggestions.
```

This `README.md` provides detailed instructions on setting up, running, and understanding the Gradio application. You can customize it further as needed.
